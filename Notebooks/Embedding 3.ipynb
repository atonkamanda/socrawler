{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demographic-sheffield",
   "metadata": {},
   "source": [
    "# Now that we have cleaned the dataset we need to do some embedding for the query and the code snippet to share the same vector space ( And therefore apply cos similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "photographic-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import csv\n",
    "import transformers\n",
    "from transformers import  AlbertConfig,TFAlbertModel\n",
    "from transformers import AlbertTokenizer\n",
    "from transformers import  AlbertConfig,TFAlbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "relevant-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "\n",
    "albert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suitable-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertConfig, AlbertForPreTraining, load_tf_weights_in_albert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "breeding-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['predictions.LayerNorm.bias', 'predictions.bias', 'albert.embeddings.position_ids', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFAlbertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlbertConfig {\n",
      "  \"_name_or_path\": \"./albert\",\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.3.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the weights and the configuration of our trained ALBERT model\n",
    "config = AlbertConfig.from_pretrained('./albert', output_hidden_states=True)\n",
    "\n",
    "model = TFAlbertModel.from_pretrained('./albert', config=config,  from_pt=True)\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "classified-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "considered-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "strategic-heritage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>function_name</th>\n",
       "      <th>lineno</th>\n",
       "      <th>original_function</th>\n",
       "      <th>function_tokens</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>url</th>\n",
       "      <th>function_tokens_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89542</td>\n",
       "      <td>espressif/esptool</td>\n",
       "      <td>ecdsa/numbertheory.py</td>\n",
       "      <td>gcd2</td>\n",
       "      <td>1</td>\n",
       "      <td>def gcd2(a, b):\\n    \"\"\"Greatest common diviso...</td>\n",
       "      <td>while return</td>\n",
       "      <td>greatest common divisor using euclid s algorithm</td>\n",
       "      <td>https://github.com/espressif/esptool/blob/mast...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74655</td>\n",
       "      <td>gwastro/pycbc</td>\n",
       "      <td>pycbc/conversions.py</td>\n",
       "      <td>chi_a</td>\n",
       "      <td>1</td>\n",
       "      <td>def chi_a(mass1, mass2, spin1z, spin2z):\\n    ...</td>\n",
       "      <td>chi return</td>\n",
       "      <td>returns the aligned mass weighted spin differe...</td>\n",
       "      <td>https://github.com/gwastro/pycbc/blob/master/p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165400</td>\n",
       "      <td>SHDShim/pytheos</td>\n",
       "      <td>pytheos/eqn_bm3.py</td>\n",
       "      <td>bm3_k</td>\n",
       "      <td>1</td>\n",
       "      <td>def bm3_k(p, v0, k0, k0p):\\n    \"\"\"\\n    calcu...</td>\n",
       "      <td>return cal</td>\n",
       "      <td>calculate bulk modulus wrapper for cal k bm3 c...</td>\n",
       "      <td>https://github.com/SHDShim/pytheos/blob/master...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177346</td>\n",
       "      <td>olsoneric/pedemath</td>\n",
       "      <td>pedemath/vec2.py</td>\n",
       "      <td>cross_v2</td>\n",
       "      <td>1</td>\n",
       "      <td>def cross_v2(vec1, vec2):\\n    \"\"\"Return the c...</td>\n",
       "      <td>cross return</td>\n",
       "      <td>return the crossproduct of the two vectors as ...</td>\n",
       "      <td>https://github.com/olsoneric/pedemath/blob/mas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285898</td>\n",
       "      <td>asweigart/pyautogui</td>\n",
       "      <td>pyautogui/__init__.py</td>\n",
       "      <td>getPointOnLine</td>\n",
       "      <td>1</td>\n",
       "      <td>def getPointOnLine(x1, y1, x2, y2, n):\\n    \"\"...</td>\n",
       "      <td>getpointonline return</td>\n",
       "      <td>returns the x y tuple of the point that has pr...</td>\n",
       "      <td>https://github.com/asweigart/pyautogui/blob/ma...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 repo                   path   function_name  \\\n",
       "0       89542    espressif/esptool  ecdsa/numbertheory.py            gcd2   \n",
       "1       74655        gwastro/pycbc   pycbc/conversions.py           chi_a   \n",
       "2      165400      SHDShim/pytheos     pytheos/eqn_bm3.py           bm3_k   \n",
       "3      177346   olsoneric/pedemath       pedemath/vec2.py        cross_v2   \n",
       "4      285898  asweigart/pyautogui  pyautogui/__init__.py  getPointOnLine   \n",
       "\n",
       "   lineno                                  original_function  \\\n",
       "0       1  def gcd2(a, b):\\n    \"\"\"Greatest common diviso...   \n",
       "1       1  def chi_a(mass1, mass2, spin1z, spin2z):\\n    ...   \n",
       "2       1  def bm3_k(p, v0, k0, k0p):\\n    \"\"\"\\n    calcu...   \n",
       "3       1  def cross_v2(vec1, vec2):\\n    \"\"\"Return the c...   \n",
       "4       1  def getPointOnLine(x1, y1, x2, y2, n):\\n    \"\"...   \n",
       "\n",
       "         function_tokens                                   docstring_tokens  \\\n",
       "0           while return   greatest common divisor using euclid s algorithm   \n",
       "1             chi return  returns the aligned mass weighted spin differe...   \n",
       "2             return cal  calculate bulk modulus wrapper for cal k bm3 c...   \n",
       "3           cross return  return the crossproduct of the two vectors as ...   \n",
       "4  getpointonline return  returns the x y tuple of the point that has pr...   \n",
       "\n",
       "                                                 url  function_tokens_count  \n",
       "0  https://github.com/espressif/esptool/blob/mast...                      2  \n",
       "1  https://github.com/gwastro/pycbc/blob/master/p...                      2  \n",
       "2  https://github.com/SHDShim/pytheos/blob/master...                      2  \n",
       "3  https://github.com/olsoneric/pedemath/blob/mas...                      2  \n",
       "4  https://github.com/asweigart/pyautogui/blob/ma...                      2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "phantom-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303256\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df['docstring_tokens'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "printable-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_head = train_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-demonstration",
   "metadata": {},
   "source": [
    "# IMPORTANT : the embedding phase can take a long time if u wish to stop, stop it via the keyboard interrupt so you can get the list of words already embedded and not go back from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "located-islam",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c446a62250e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malbert_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Batch size 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m768\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\transformers\\models\\albert\\modeling_tf_albert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[0;32m    871\u001b[0m         )\n\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m         outputs = self.albert(\n\u001b[0m\u001b[0;32m    874\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"attention_mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\transformers\\models\\albert\\modeling_tf_albert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"training\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         )\n\u001b[1;32m--> 677\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    678\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\transformers\\models\\albert\\modeling_tf_albert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mgroup_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_groups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m             layer_group_output = self.albert_layer_groups[group_idx](\n\u001b[0m\u001b[0;32m    475\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\transformers\\models\\albert\\modeling_tf_albert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, training)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             layer_output = albert_layer(\n\u001b[0m\u001b[0;32m    418\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\transformers\\models\\albert\\modeling_tf_albert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, hidden_states, attention_mask, head_mask, output_attentions, training)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m         \u001b[0mffn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m     return core_ops.dense(\n\u001b[0m\u001b[0;32m   1194\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\ops\\core.py\u001b[0m in \u001b[0;36mdense\u001b[1;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[0;32m     54\u001b[0m   \u001b[1;31m# Broadcast kernel to inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes, name)\u001b[0m\n\u001b[0;32m   4523\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mab_matmul\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4524\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4525\u001b[1;33m         return array_ops.reshape(\n\u001b[0m\u001b[0;32m   4526\u001b[0m             ab_matmul, a_free_dims + b_free_dims, name=name)\n\u001b[0;32m   4527\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m   \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8225\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8226\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8227\u001b[1;33m       return reshape_eager_fallback(\n\u001b[0m\u001b[0;32m   8228\u001b[0m           tensor, shape, name=name, ctx=_ctx)\n\u001b[0;32m   8229\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[1;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[0;32m   8250\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8251\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tshape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8252\u001b[1;33m   _result = _execute.execute(b\"Reshape\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0m\u001b[0;32m   8253\u001b[0m                              ctx=ctx, name=name)\n\u001b[0;32m   8254\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\codesearch\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_embeddings = []\n",
    "for count,item in enumerate(train_df['docstring_tokens'].values): #traverse thorugh all train data set docstrings\n",
    "    e = albert_tokenizer.encode(item, max_length=512)\n",
    "    input = tf.constant(e)[None, :]  # Batch size 1 \n",
    "    output = model(input)\n",
    "    v = [0]*768\n",
    "    for i in range(1, len(input[0])-1):\n",
    "        v = v + output[0][0][i].numpy()  # generate sentence vectors by averaging the word vectors\n",
    "    avg_embeddings.append(v/len(input[0])) #append all sentence vectors into a list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-percentage",
   "metadata": {},
   "source": [
    "# Save it in a \"tsv\" file, tsv files are shared vector representation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "binary-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"avg_embeddings.tsv\",\"w+\",newline='') as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter='\\t')\n",
    "    csvWriter.writerows(avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "quarterly-ghana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "complete-listening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.16839517e-02  6.88348025e-01  6.39434850e-01 -4.71354170e-01\n",
      " -4.03322669e-01  7.85256037e-02  1.16616547e-01 -3.81152095e-01\n",
      "  1.75100972e-01 -3.96167673e-01  3.81783211e-01  1.36544413e+00\n",
      "  9.62476909e-01 -3.75559979e-01 -1.16728918e+00 -4.25497208e-01\n",
      " -3.73788972e-01 -2.11227715e-01 -4.07284307e-01  2.28629363e+00\n",
      " -3.38343913e-01 -2.32977846e-01  9.42843235e-01  4.41283967e-01\n",
      "  4.94421538e-01 -9.63364097e-01 -2.40779852e-01  1.55508692e-01\n",
      "  1.45130007e+00 -2.54643968e-01  3.33144273e-01 -4.86735974e-01\n",
      " -5.08385569e-01 -4.22468544e-01 -7.63946547e-01  1.76803382e-01\n",
      "  4.38505408e-02 -5.78720345e-01  8.17443598e-01 -8.25267839e-02\n",
      "  4.59012662e-01  7.93389394e-01 -1.84188743e+00 -7.38303846e-01\n",
      "  4.77419954e-01  7.41540783e-01 -5.93035770e-01 -7.14947515e-01\n",
      " -6.70461059e-01 -1.55738020e+00  4.82279084e-01  1.52183481e+00\n",
      " -9.43557973e-01 -6.79263050e-01  4.77522809e-01 -5.75293267e-01\n",
      " -8.68631369e-02  1.80469356e-01  8.26092188e-01 -1.13392010e+00\n",
      "  6.04530831e-01 -2.87263390e-01  3.96641359e-01 -5.17264974e-01\n",
      "  1.36597760e+00  7.24582204e-01 -2.31379419e-01  1.28330943e-02\n",
      " -4.18536555e-01  5.43628086e-01  3.40827456e-01 -1.37518237e-01\n",
      " -7.39537175e-01  1.31938013e-01 -1.43317233e-01  4.55459882e-01\n",
      " -4.00427536e-01  1.56637058e+00  9.53644317e-01 -6.34388287e-01\n",
      " -1.07724958e+00  9.01362703e-01  5.74331736e-01 -2.01425724e+00\n",
      " -3.95653479e-01 -1.56301671e+00 -3.62482435e-02  9.04181962e-01\n",
      " -1.15601226e+00  1.04556160e+00  1.13322452e+00  4.35896973e-01\n",
      "  4.60254802e-01  7.38932334e-01 -4.90341217e-02 -3.70401403e-01\n",
      "  4.68324829e-01  1.81846815e-01 -4.90469261e-01  5.60017179e-01\n",
      "  3.64255120e-01  2.95926040e-01 -9.63714937e-01 -7.04472517e-01\n",
      " -3.03880513e-01 -1.05110518e+00 -7.06966609e-02 -8.16918009e-01\n",
      "  1.28064141e+00  7.81141485e-01 -1.46726548e+00 -1.53719267e-01\n",
      "  7.38316417e-01  6.88821582e-01  5.42946922e-01  2.93109591e-01\n",
      " -2.06536393e-01  3.53509200e-01 -3.15202801e-02  1.00544261e+00\n",
      "  1.84403294e+00  5.36800826e-01 -2.62963144e-01 -3.61473117e-01\n",
      " -1.22419272e-01 -7.43945456e-01 -1.46626785e-01 -7.67444629e-01\n",
      " -1.12424736e+00 -1.10966580e+00 -2.79308744e-02  7.84132465e-01\n",
      " -7.83398129e-01 -1.52176501e+00  1.15859078e-01 -5.74785943e-01\n",
      " -8.04304591e-01  6.18791793e-01 -3.66138218e-01  2.86977525e-01\n",
      "  6.61752623e-01  8.12324299e-02  1.03743472e-02 -1.28313957e+00\n",
      " -2.74490166e-01  4.06507067e-01 -5.94651705e-02 -6.85351660e-02\n",
      " -1.78307468e+00 -1.58959227e-01 -8.11102858e-01 -4.33637144e-01\n",
      " -5.14045234e-01  4.23420973e-01  6.47648986e-01 -6.63393532e-01\n",
      "  1.03356086e+00  5.73861355e-01 -5.27851341e-02 -4.82250881e-01\n",
      "  4.31292679e-01  3.42128617e-01  2.64206107e-01  2.81350623e-01\n",
      "  8.18358213e-01 -4.86775970e-01 -3.13711143e-01 -6.70031754e-01\n",
      " -1.17799542e+00  2.48519750e-01 -1.73401333e-01  5.25382191e-01\n",
      " -3.59461330e-01  5.48341119e-01  3.62664822e-01 -4.59822785e-01\n",
      "  7.34068559e-01  3.16952636e-01 -4.81379182e-01 -1.05363978e+00\n",
      " -2.70916516e-01 -8.41525238e-01 -9.07543623e-01 -4.26293664e-01\n",
      "  2.67127893e-01  2.70116051e-01  7.89184435e-01 -4.45799352e-01\n",
      " -8.36681325e-01  6.48422896e-01 -1.93808524e-01  1.02953203e+00\n",
      " -2.11603989e-01  6.39973538e-01  4.14817784e-01 -5.38720924e-01\n",
      " -8.66673229e-01 -4.28579406e-01  5.53683411e-01  3.66774299e-01\n",
      "  2.15071067e+00 -6.45373230e-01  2.37624676e-01 -4.72647818e-01\n",
      " -2.94443108e+00  1.05990309e+00 -5.12096282e-01  7.66167073e-01\n",
      "  8.71389427e-02  4.37846594e-01 -9.67438079e-01 -1.19450190e-02\n",
      "  9.55242707e-01 -2.38281710e-01  1.68377052e+00  5.82113018e-01\n",
      "  3.08390954e-01  8.46080420e-01  9.76258315e-01  1.36028994e+00\n",
      "  8.29944299e-01  8.01800214e-01  8.68501815e-01 -1.76628255e-02\n",
      "  2.51847758e-02 -1.61870410e+00  8.82745245e-01 -1.29021732e-01\n",
      "  1.76224823e+00 -6.10916478e-01  2.02115255e-01  8.68755866e-03\n",
      "  8.54324686e-01 -3.59407300e-01  8.96859268e-01  5.64607267e-02\n",
      "  5.59796083e-01 -9.74706242e-01 -2.14449076e+00 -1.91904814e-01\n",
      "  1.34048478e+00 -1.17061897e+00  1.80601721e-01  7.49735096e-01\n",
      "  2.33618035e-01 -6.30316152e-01  4.33384482e-01 -1.67750753e-02\n",
      "  2.44396587e-01  9.59481067e-01  1.65282221e-01 -7.11444314e-01\n",
      "  7.94462397e-01  1.64609183e+00  4.59790968e-01  8.72562386e-01\n",
      " -2.37806678e-01  1.31591944e-01  1.84428893e+00 -1.02068973e-01\n",
      " -1.60059615e-01  6.83241527e-02 -2.61872179e-02  1.55110473e+00\n",
      "  4.38156940e-01  7.32322185e-01  1.27893401e-01  2.30824278e-01\n",
      "  1.51247489e-01 -7.03805735e-01  9.87422526e-01  4.73910582e-01\n",
      " -2.95818030e+00  4.64202986e-01  6.24798212e-01 -5.06035480e-01\n",
      "  2.47579290e-01 -6.30676509e-02 -9.12389038e-01  4.60170217e-01\n",
      "  8.20656226e-01  4.59858164e-01  6.07526463e-02  6.59211200e-01\n",
      " -2.12378777e+00 -8.21280520e-01  2.07615498e+00  3.43807957e-01\n",
      "  1.11967615e+00 -1.11340561e+00 -2.38989395e-01  1.49875001e+00\n",
      "  8.93849673e-01 -2.06071385e-02 -3.26678349e-01 -9.28094437e-01\n",
      "  2.59209906e-01 -1.15449907e-02  3.81620364e-01 -8.46057402e-01\n",
      " -5.56788549e-01  1.82610574e-02 -2.20146005e-01 -6.18867099e-01\n",
      " -1.38424363e+00 -1.51374441e+00 -1.15363884e+00 -8.97296596e-01\n",
      " -1.27013786e+00 -1.37295242e+00  3.97644857e-01 -2.73997504e-01\n",
      "  3.94864999e-01 -6.36037565e-01  1.13127313e+00 -2.65771976e-02\n",
      "  8.40681787e-01 -1.43580507e+00 -5.95908341e-01  4.16470830e-01\n",
      " -4.57273137e-01  2.32762366e-01  5.87211625e-02  1.26326856e+00\n",
      "  2.33264928e-01  3.27843188e-01  1.49835750e-01  1.07075495e-01\n",
      " -6.36547151e-01 -2.31430975e-01 -4.90235475e-01  1.71491687e+00\n",
      " -4.92156667e-02 -2.95472862e-01  7.36900873e-01 -1.68069061e-01\n",
      " -4.13508099e-01 -5.86665239e-01  6.25242236e-01 -3.29846416e-01\n",
      " -2.47633786e-01 -8.18940701e-01  1.15304111e-01 -3.37803037e-01\n",
      "  8.14308213e-01 -5.28731986e-01  1.17313304e+00 -5.50539032e-01\n",
      " -9.78255056e-01 -8.89860658e-02 -4.51268300e-02 -1.43635112e-01\n",
      " -1.56977785e+00 -3.86095402e-02  7.78845342e-01 -3.28536289e-01\n",
      "  8.40558282e-02 -2.85075876e-01 -6.41151800e-01 -6.18126978e-01\n",
      " -1.68349342e+00 -7.51812696e-01  7.11034312e-01  1.07933038e+00\n",
      " -1.72040538e-01  1.58913038e-01  1.32109702e+00 -9.39123752e-01\n",
      " -3.44182347e-01  1.14068916e+00  1.26099967e+00 -5.33536519e-02\n",
      " -1.90496126e+00  7.39021654e-02  4.94429228e-01 -5.24173892e-01\n",
      "  6.46997408e-01  1.26595733e-01  1.09723767e+00  7.33504591e-01\n",
      "  3.82335303e-01 -7.76664213e-01  2.66725556e-01 -6.30121224e-01\n",
      " -8.76005182e-01  9.75296011e-01  8.60292485e-01 -4.57019885e-02\n",
      " -3.94342763e-01  1.77814104e+00 -3.82069753e-01  1.04373417e+00\n",
      "  1.01807781e+00  5.27844651e-01 -2.46995554e-01 -1.95328269e-01\n",
      "  2.12569565e+00  1.09778697e+00 -3.24658672e-01 -3.70199852e-01\n",
      " -5.44083111e-01 -6.52858632e-01 -1.09706759e+00  1.59641890e+00\n",
      " -8.19125336e-01 -1.83871270e-01 -1.32003918e-01  1.38982900e+00\n",
      "  6.00112130e-01  3.26825301e-01 -4.39286457e-01  3.43899691e-01\n",
      " -4.92816111e-01 -1.63992468e+00  3.42256956e-01 -1.48165509e+00\n",
      " -9.80796172e-01 -1.64615680e-01 -1.37009411e+00 -8.55964569e-01\n",
      "  5.06954279e-01 -3.09973399e-01  5.90414027e-01 -1.16979586e+00\n",
      " -1.96903616e-01 -1.09117117e+00 -1.56239796e-01 -4.70675411e-01\n",
      "  3.78630728e-01 -2.07639162e-01  5.60298544e-01 -2.28070297e-01\n",
      "  5.69944742e-01  7.55552048e-02  1.07372951e+00  4.63394674e-01\n",
      " -3.19834279e-01  2.08813864e-01 -2.38866985e-01 -6.45813322e-01\n",
      "  1.67174988e-01 -1.41975650e-02 -1.19338876e-01  1.37406599e+00\n",
      "  2.52422223e-01  6.56209937e-01 -5.14836005e-01  3.03792666e-01\n",
      "  3.35560839e-02  5.23748345e-01 -1.76776324e-01  2.57733830e-01\n",
      "  1.15955416e+00  2.82710647e-02  1.29590911e-01 -4.92443787e-01\n",
      "  4.47009907e-01  2.09343979e-02 -3.10243755e-02  5.19004783e-01\n",
      " -4.14715408e-01  9.58254482e-01 -4.26487034e-01 -7.08746605e-01\n",
      " -6.38511338e-01  1.13259517e-01  8.67188146e-01  1.16612782e+00\n",
      " -1.23970900e+00  7.81389178e-01 -9.52379534e-01 -6.59646956e-01\n",
      " -2.37481713e-01 -1.94226568e-01  6.85540251e-01  3.00082270e-01\n",
      "  1.01543207e-01  9.10044581e-01 -1.53161807e+00 -4.31176349e-01\n",
      " -1.38771175e+00 -1.09845624e+00 -1.28090847e-01  6.72734002e-01\n",
      " -1.68196124e-01  8.53981678e-01  1.91153189e-01 -7.71808858e-01\n",
      "  5.42428224e-01  3.56103444e-02  4.40182870e-01  1.73752297e-01\n",
      "  2.29896928e-01 -1.28896358e+00  3.25143138e-01 -1.67926431e-01\n",
      "  6.65388188e-02 -2.56313713e-02  3.47140128e-01  2.53383781e-01\n",
      " -2.57691456e-01 -3.66944478e-01 -4.56927034e-01  5.21606173e-01\n",
      "  1.03611021e+00  1.11537897e-01  8.85396769e-01 -1.12312349e+00\n",
      "  5.07959323e-01 -7.91320986e-01  3.20696973e-01  5.76913836e-01\n",
      "  1.31091729e+00  1.56942583e-02 -1.31641139e-01 -9.01798026e-01\n",
      " -1.78871631e+00 -4.13123379e-02 -1.47930294e+00 -8.87081445e-02\n",
      "  2.63336413e-01 -2.60084935e-01  9.71663585e-01  8.43668997e-01\n",
      " -3.16996718e-01  1.04163979e+00 -1.60065664e-01  1.50839368e-01\n",
      "  3.84219911e-01 -7.15231549e-01  3.97956831e-01 -5.35142289e-01\n",
      "  9.52648330e-01  1.71486882e-01  7.57156024e-01 -3.54824821e-01\n",
      "  1.50812899e+00 -9.51377596e-01 -8.50144840e-02  5.77292536e-01\n",
      "  7.67485754e-01 -1.09427204e+00 -3.59833651e-01  1.03392623e+00\n",
      "  4.45063202e-01  1.06861700e+00  2.02735737e-01 -4.91573513e-02\n",
      " -8.31458546e-02 -6.73105648e-01  9.24178256e-01 -3.26023710e-01\n",
      " -7.91255292e-01  5.80726481e-01 -7.74683455e-01  5.54808551e-01\n",
      " -7.83727164e-01  3.11656107e-01 -4.20243155e-01 -5.27839180e-01\n",
      " -6.06765705e-01 -1.29534294e+00 -7.27945372e-01  6.18298273e-01\n",
      "  6.18598513e-02  4.84613581e-01 -7.59457086e-02  6.59311898e-02\n",
      " -5.49429661e-02  1.81490140e+00  7.24360600e-01  7.81482905e-01\n",
      "  1.20707649e+00 -8.03533265e-01 -1.77943006e-01  1.12434634e-01\n",
      " -1.25452161e+00 -1.57100800e-03  1.98238428e-01  1.02793904e+00\n",
      " -9.13087996e-01  6.79705349e-03 -2.05255232e-01 -6.54770538e-01\n",
      " -1.21534331e-01 -3.68348099e-02  1.65741513e+00  1.04986579e+00\n",
      "  8.86769542e-01  4.91179859e-01 -6.57519753e-01  3.33727743e-01\n",
      " -1.27330163e+00  4.46893318e-02 -9.11177984e-01 -8.52190365e-01\n",
      "  3.93210533e-01 -5.92194367e-01  1.01213546e+00  9.10274793e-02\n",
      " -8.14824045e-01 -1.35833972e-01  1.47052763e-01 -9.79203348e-01\n",
      " -4.35257707e-01 -6.23296168e-01 -8.38176319e-01 -5.78974317e-01\n",
      " -1.14739682e+00  2.58119320e-01  6.33543691e-01 -7.75381306e-01\n",
      " -1.46895353e+00  8.44453133e-01 -1.09660903e-01 -4.91943811e-01\n",
      " -2.40749877e-01 -5.23165537e-01 -1.18481162e+00 -6.42057070e-01\n",
      " -1.18498608e+00  1.50546515e+00  1.54715330e-01 -2.55015751e-01\n",
      "  5.43552816e-01 -1.35712017e+00  1.48641512e+00 -4.19422997e-01\n",
      " -4.22028100e-01 -4.41278349e-01 -1.14251670e-01  3.16876107e-02\n",
      "  6.83331276e-01 -1.19993984e+00 -1.45219870e+00  3.89991280e-01\n",
      " -3.32801128e-01  2.14081530e-01 -7.98432701e-01  2.96011014e-01\n",
      " -3.05220993e-01 -7.80076852e-02 -2.28828163e-01  8.85929062e-01\n",
      " -4.93916070e-01  9.69593676e-01  6.12233192e-01  4.35926322e-01\n",
      "  1.05590326e+00 -1.29206250e+00  4.53474966e-01 -2.13712285e-01\n",
      "  5.15127116e-01 -1.62433201e-01  1.48768300e+00 -9.98620760e-01\n",
      " -1.22319697e+00 -1.75652316e-01 -1.61057345e+00 -1.55584456e-01\n",
      "  6.54306205e-02  9.54230127e-01  2.06791784e-01  1.53882694e-01\n",
      " -1.12319458e+00  7.27339923e-01  4.80420304e-01  7.81156792e-01\n",
      " -7.51542804e-02  7.98894868e-01  7.59951002e-01  7.52544866e-01\n",
      " -1.23042983e+00  6.56653724e-01  2.59018372e-01 -1.74452375e+00\n",
      "  2.10093410e+00 -7.15524656e-01  2.72609626e-01 -9.45376078e-01\n",
      "  4.17324946e-01  3.20000403e-01  4.89698934e-01  8.74034448e-01\n",
      " -9.28145578e-02 -1.02556127e-01 -1.37748075e+00 -6.45822046e-01\n",
      "  3.11887146e-01 -4.35384961e-01  2.26408919e-02  5.25767941e-01\n",
      "  8.11614467e-02  5.99097756e-01  2.05521819e+00 -3.19205051e-02\n",
      "  5.86442597e-01 -1.33666593e+00  1.10471850e+00  4.92990073e-01\n",
      " -4.94011236e-01 -3.18196113e-01 -1.77512566e-01  8.90215557e-01\n",
      "  1.65806706e-01  9.42202772e-03  9.63278262e-01  6.37999530e-01\n",
      " -2.61126291e-01 -7.86161902e-01 -8.47526683e-01 -1.19471408e-01\n",
      "  1.30869975e+00 -1.00220007e+00 -2.72566166e+00  4.49974249e-01\n",
      " -5.22468698e-02  1.26395329e+00  1.10379299e-01  1.76704758e+00\n",
      "  3.33352023e-01  3.21700235e-02 -7.64484770e-01  1.45432535e+00\n",
      " -2.35777651e-01 -1.79944158e+00  5.28472833e-01  2.11658564e-01\n",
      "  3.01968074e-02  1.27836273e-01  2.22432415e-01 -1.87572510e+00\n",
      " -2.23959108e-01  3.65875812e-01  1.12899614e+00 -1.07573350e+00\n",
      " -6.28846244e-01  7.65262409e-01 -1.39435818e+00 -3.57555375e-01\n",
      " -1.12412041e-01  3.67865472e-01 -2.70882555e-01 -2.28860244e+00\n",
      " -3.19565651e-01  6.53328584e-01 -1.29996454e-01  1.28486477e-01\n",
      "  3.26006879e-01  5.79407347e-01  5.03175701e-01 -3.92127654e-01\n",
      " -9.44206990e-01  4.12092479e-01  9.35070207e-01  5.76274452e-02\n",
      " -3.20452244e-01 -4.58646545e-01  9.31886989e-01 -1.31910855e+00\n",
      "  7.30720898e-01 -1.17331499e+00 -6.03762330e-01  5.64831811e-01\n",
      "  3.87193789e-01  8.24123867e-02 -2.04496417e-01  7.00141929e-01]\n"
     ]
    }
   ],
   "source": [
    "print(avg_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-median",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codesearch",
   "language": "python",
   "name": "codesearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
